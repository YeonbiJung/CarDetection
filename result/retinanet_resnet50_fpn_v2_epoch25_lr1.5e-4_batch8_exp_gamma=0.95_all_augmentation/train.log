2023-11-10 03:21:32,962 | train | INFO | Set Logger /home/kwy00/ysy/results/train/20231110_031722
2023-11-10 03:21:33,137 | train | INFO | Load data, train:38367 val:1000
2023-11-10 03:21:33,137 | train | INFO | Initiated early stopper, mode: min, best score: inf, patience: 10
2023-11-10 03:21:33,863 | train | INFO | --Train 0/5
2023-11-10 03:21:40,374 | train | INFO | batch: 0/4796 loss: 0.02090103179216385
2023-11-10 03:24:24,637 | train | INFO | batch: 100/4796 loss: 0.022942043840885162
2023-11-10 03:27:10,024 | train | INFO | batch: 200/4796 loss: 0.010595619678497314
2023-11-10 03:29:55,903 | train | INFO | batch: 300/4796 loss: 0.022827643901109695
2023-11-10 03:32:41,146 | train | INFO | batch: 400/4796 loss: 0.014337074011564255
2023-11-10 03:35:24,606 | train | INFO | batch: 500/4796 loss: 0.008484091609716415
2023-11-10 03:38:09,739 | train | INFO | batch: 600/4796 loss: 0.01246027834713459
2023-11-10 03:40:52,667 | train | INFO | batch: 700/4796 loss: 0.018284250050783157
2023-11-10 03:43:37,702 | train | INFO | batch: 800/4796 loss: 0.011611396446824074
2023-11-10 03:46:20,606 | train | INFO | batch: 900/4796 loss: 0.02234884910285473
2023-11-10 03:49:01,309 | train | INFO | batch: 1000/4796 loss: 0.019607849419116974
2023-11-10 03:51:43,562 | train | INFO | batch: 1100/4796 loss: 0.06596565991640091
2023-11-10 03:54:25,246 | train | INFO | batch: 1200/4796 loss: 0.008151475340127945
2023-11-10 03:57:04,568 | train | INFO | batch: 1300/4796 loss: 0.007771844509989023
2023-11-10 03:59:45,851 | train | INFO | batch: 1400/4796 loss: 0.015743546187877655
2023-11-10 04:02:28,096 | train | INFO | batch: 1500/4796 loss: 0.035994164645671844
2023-11-10 04:05:11,759 | train | INFO | batch: 1600/4796 loss: 0.012575123459100723
2023-11-10 04:07:52,749 | train | INFO | batch: 1700/4796 loss: 0.011005628854036331
2023-11-10 04:10:34,904 | train | INFO | batch: 1800/4796 loss: 0.01916803978383541
2023-11-10 04:13:16,731 | train | INFO | batch: 1900/4796 loss: 0.015734249725937843
2023-11-10 04:15:58,022 | train | INFO | batch: 2000/4796 loss: 0.021023375913500786
2023-11-10 04:18:40,267 | train | INFO | batch: 2100/4796 loss: 0.009025807492434978
2023-11-10 04:21:21,512 | train | INFO | batch: 2200/4796 loss: 0.024297945201396942
2023-11-10 04:24:02,450 | train | INFO | batch: 2300/4796 loss: 0.013626599684357643
2023-11-10 04:26:43,657 | train | INFO | batch: 2400/4796 loss: 0.008554931730031967
2023-11-10 04:29:24,824 | train | INFO | batch: 2500/4796 loss: 0.05416816845536232
2023-11-10 04:32:05,507 | train | INFO | batch: 2600/4796 loss: 0.026979515329003334
2023-11-10 04:34:45,851 | train | INFO | batch: 2700/4796 loss: 0.009111299179494381
2023-11-10 04:37:25,937 | train | INFO | batch: 2800/4796 loss: 0.020610079169273376
2023-11-10 04:40:06,224 | train | INFO | batch: 2900/4796 loss: 0.011384036391973495
2023-11-10 04:42:48,923 | train | INFO | batch: 3000/4796 loss: 0.014189338311553001
2023-11-10 04:45:33,160 | train | INFO | batch: 3100/4796 loss: 0.029903031885623932
2023-11-10 04:48:15,391 | train | INFO | batch: 3200/4796 loss: 0.010003101080656052
2023-11-10 04:50:58,422 | train | INFO | batch: 3300/4796 loss: 0.12607313692569733
2023-11-10 04:53:40,489 | train | INFO | batch: 3400/4796 loss: 0.010824503377079964
2023-11-10 04:56:22,255 | train | INFO | batch: 3500/4796 loss: 0.021759552881121635
2023-11-10 04:59:05,375 | train | INFO | batch: 3600/4796 loss: 0.0356903076171875
2023-11-10 05:01:46,396 | train | INFO | batch: 3700/4796 loss: 0.013158868998289108
2023-11-10 05:04:29,466 | train | INFO | batch: 3800/4796 loss: 0.009769311174750328
2023-11-10 05:07:10,860 | train | INFO | batch: 3900/4796 loss: 0.014025676064193249
2023-11-10 05:09:52,707 | train | INFO | batch: 4000/4796 loss: 0.008304009214043617
2023-11-10 05:12:35,519 | train | INFO | batch: 4100/4796 loss: 0.01338605210185051
2023-11-10 05:15:15,043 | train | INFO | batch: 4200/4796 loss: 0.008045732043683529
2023-11-10 05:17:55,912 | train | INFO | batch: 4300/4796 loss: 0.009354079142212868
2023-11-10 05:20:38,989 | train | INFO | batch: 4400/4796 loss: 0.006474874913692474
2023-11-10 05:23:20,815 | train | INFO | batch: 4500/4796 loss: 0.007891461253166199
2023-11-10 05:26:02,737 | train | INFO | batch: 4600/4796 loss: 0.023734284564852715
2023-11-10 05:28:44,647 | train | INFO | batch: 4700/4796 loss: 0.02288421243429184
2023-11-10 05:31:23,881 | train | INFO | --Val 0/5
2023-11-10 05:31:25,076 | train | INFO | batch: 0/125 loss: 0.010714737698435783
2023-11-10 05:33:21,822 | train | INFO | batch: 100/125 loss: 0.01098619494587183
2023-11-10 05:33:49,878 | train | INFO | Write row 0
2023-11-10 05:33:50,737 | train | INFO | Recorder, epoch 0 Model saved: /home/kwy00/ysy/results/train/20231110_031722/model.pt
2023-11-10 05:33:50,738 | train | INFO | --Train 1/5
2023-11-10 05:33:52,316 | train | INFO | batch: 0/4796 loss: 0.014798266813158989
2023-11-10 05:36:35,635 | train | INFO | batch: 100/4796 loss: 0.01945490762591362
2023-11-10 05:39:18,379 | train | INFO | batch: 200/4796 loss: 0.024518785998225212
2023-11-10 05:42:00,299 | train | INFO | batch: 300/4796 loss: 0.01976160518825054
2023-11-10 05:44:43,087 | train | INFO | batch: 400/4796 loss: 0.011878345161676407
2023-11-10 05:47:26,093 | train | INFO | batch: 500/4796 loss: 0.013098405674099922
2023-11-10 05:50:07,707 | train | INFO | batch: 600/4796 loss: 0.00881967693567276
2023-11-10 05:52:50,468 | train | INFO | batch: 700/4796 loss: 0.024087999016046524
2023-11-10 05:55:34,260 | train | INFO | batch: 800/4796 loss: 0.02512330561876297
2023-11-10 05:58:16,730 | train | INFO | batch: 900/4796 loss: 0.009920667856931686
2023-11-10 06:01:00,118 | train | INFO | batch: 1000/4796 loss: 0.011680920608341694
2023-11-10 06:03:42,654 | train | INFO | batch: 1100/4796 loss: 0.007431504782289267
2023-11-10 06:06:25,321 | train | INFO | batch: 1200/4796 loss: 0.007587052881717682
2023-11-10 06:09:07,472 | train | INFO | batch: 1300/4796 loss: 0.020138874650001526
2023-11-10 06:11:50,425 | train | INFO | batch: 1400/4796 loss: 0.03167291358113289
2023-11-10 06:14:31,803 | train | INFO | batch: 1500/4796 loss: 0.01070707943290472
2023-11-10 06:17:14,450 | train | INFO | batch: 1600/4796 loss: 0.024148454889655113
2023-11-10 06:19:58,462 | train | INFO | batch: 1700/4796 loss: 0.03319574147462845
2023-11-10 06:22:41,087 | train | INFO | batch: 1800/4796 loss: 0.010257890447974205
2023-11-10 06:25:22,936 | train | INFO | batch: 1900/4796 loss: 0.015339439734816551
2023-11-10 06:28:05,362 | train | INFO | batch: 2000/4796 loss: 0.00963417999446392
2023-11-10 06:30:48,093 | train | INFO | batch: 2100/4796 loss: 0.006922808010131121
2023-11-10 06:33:30,906 | train | INFO | batch: 2200/4796 loss: 0.008514303714036942
2023-11-10 06:36:13,975 | train | INFO | batch: 2300/4796 loss: 0.008215035311877728
2023-11-10 06:38:55,323 | train | INFO | batch: 2400/4796 loss: 0.009979532100260258
2023-11-10 06:41:39,003 | train | INFO | batch: 2500/4796 loss: 0.009471300058066845
2023-11-10 06:44:20,872 | train | INFO | batch: 2600/4796 loss: 0.010843195952475071
2023-11-10 06:47:04,932 | train | INFO | batch: 2700/4796 loss: 0.025203200057148933
2023-11-10 06:49:46,452 | train | INFO | batch: 2800/4796 loss: 0.006864095106720924
2023-11-10 06:52:28,793 | train | INFO | batch: 2900/4796 loss: 0.008827191777527332
2023-11-10 06:55:12,319 | train | INFO | batch: 3000/4796 loss: 0.016891073435544968
2023-11-10 06:57:54,197 | train | INFO | batch: 3100/4796 loss: 0.015290933661162853
2023-11-10 07:00:37,195 | train | INFO | batch: 3200/4796 loss: 0.013023514300584793
2023-11-10 07:03:19,497 | train | INFO | batch: 3300/4796 loss: 0.010646231472492218
2023-11-10 07:06:02,328 | train | INFO | batch: 3400/4796 loss: 0.007390123326331377
2023-11-10 07:08:44,557 | train | INFO | batch: 3500/4796 loss: 0.007988126948475838
2023-11-10 07:11:28,169 | train | INFO | batch: 3600/4796 loss: 0.01169377937912941
2023-11-10 07:14:10,992 | train | INFO | batch: 3700/4796 loss: 0.010874433442950249
2023-11-10 07:16:53,239 | train | INFO | batch: 3800/4796 loss: 0.08301293849945068
2023-11-10 07:19:35,233 | train | INFO | batch: 3900/4796 loss: 0.03766521066427231
2023-11-10 07:22:18,645 | train | INFO | batch: 4000/4796 loss: 0.012189572677016258
2023-11-10 07:25:01,397 | train | INFO | batch: 4100/4796 loss: 0.026012059301137924
2023-11-10 07:27:45,412 | train | INFO | batch: 4200/4796 loss: 0.03242717683315277
2023-11-10 07:30:26,753 | train | INFO | batch: 4300/4796 loss: 0.010613095946609974
2023-11-10 07:33:10,033 | train | INFO | batch: 4400/4796 loss: 0.009991313330829144
2023-11-10 07:35:53,862 | train | INFO | batch: 4500/4796 loss: 0.006077676545828581
2023-11-10 07:38:36,250 | train | INFO | batch: 4600/4796 loss: 0.04470078647136688
2023-11-10 07:41:19,700 | train | INFO | batch: 4700/4796 loss: 0.008376789279282093
2023-11-10 07:43:54,699 | train | INFO | --Val 1/5
2023-11-10 07:43:55,872 | train | INFO | batch: 0/125 loss: 0.008630642667412758
2023-11-10 07:45:51,601 | train | INFO | batch: 100/125 loss: 0.00873156264424324
2023-11-10 07:46:19,323 | train | INFO | Write row 1
2023-11-10 07:46:19,764 | train | INFO | --Train 2/5
2023-11-10 07:46:21,033 | train | INFO | batch: 0/4796 loss: 0.04241745173931122
2023-11-10 07:49:04,951 | train | INFO | batch: 100/4796 loss: 0.011422425508499146
2023-11-10 07:51:47,113 | train | INFO | batch: 200/4796 loss: 0.010945828631520271
2023-11-10 07:54:31,385 | train | INFO | batch: 300/4796 loss: 0.019779203459620476
2023-11-10 07:57:15,809 | train | INFO | batch: 400/4796 loss: 0.01107686199247837
2023-11-10 07:59:58,558 | train | INFO | batch: 500/4796 loss: 0.00759853282943368
2023-11-10 08:02:42,849 | train | INFO | batch: 600/4796 loss: 0.01038305927067995
2023-11-10 08:05:25,542 | train | INFO | batch: 700/4796 loss: 0.014821739867329597
2023-11-10 08:08:08,849 | train | INFO | batch: 800/4796 loss: 0.02180430479347706
2023-11-10 08:10:51,859 | train | INFO | batch: 900/4796 loss: 0.014142819680273533
2023-11-10 08:13:34,088 | train | INFO | batch: 1000/4796 loss: 0.00804080069065094
2023-11-10 08:16:18,218 | train | INFO | batch: 1100/4796 loss: 0.010515945963561535
2023-11-10 08:19:01,968 | train | INFO | batch: 1200/4796 loss: 0.0081220343708992
2023-11-10 08:21:44,677 | train | INFO | batch: 1300/4796 loss: 0.011298567056655884
2023-11-10 08:24:25,847 | train | INFO | batch: 1400/4796 loss: 0.009263308718800545
2023-11-10 08:27:07,343 | train | INFO | batch: 1500/4796 loss: 0.008779097348451614
2023-11-10 08:29:50,410 | train | INFO | batch: 1600/4796 loss: 0.022471226751804352
2023-11-10 08:32:32,461 | train | INFO | batch: 1700/4796 loss: 0.006348093040287495
2023-11-10 08:35:17,658 | train | INFO | batch: 1800/4796 loss: 0.010372539982199669
2023-11-10 08:38:00,556 | train | INFO | batch: 1900/4796 loss: 0.008597217500209808
2023-11-10 08:40:43,902 | train | INFO | batch: 2000/4796 loss: 0.0194595567882061
2023-11-10 08:43:25,856 | train | INFO | batch: 2100/4796 loss: 0.006920297164469957
2023-11-10 08:46:09,597 | train | INFO | batch: 2200/4796 loss: 0.01395903155207634
2023-11-10 08:48:52,671 | train | INFO | batch: 2300/4796 loss: 0.007196532562375069
2023-11-10 08:51:36,809 | train | INFO | batch: 2400/4796 loss: 0.04285188391804695
2023-11-10 08:54:19,063 | train | INFO | batch: 2500/4796 loss: 0.01601654663681984
2023-11-10 08:57:02,137 | train | INFO | batch: 2600/4796 loss: 0.00883250031620264
2023-11-10 08:59:44,571 | train | INFO | batch: 2700/4796 loss: 0.0096261752769351
2023-11-10 09:02:27,526 | train | INFO | batch: 2800/4796 loss: 0.018742594867944717
2023-11-10 09:05:12,526 | train | INFO | batch: 2900/4796 loss: 0.021318845450878143
2023-11-10 09:07:55,780 | train | INFO | batch: 3000/4796 loss: 0.02272290363907814
2023-11-10 09:10:38,444 | train | INFO | batch: 3100/4796 loss: 0.019337540492415428
2023-11-10 09:13:21,425 | train | INFO | batch: 3200/4796 loss: 0.012217825278639793
2023-11-10 09:16:05,352 | train | INFO | batch: 3300/4796 loss: 0.0474730022251606
2023-11-10 09:18:49,579 | train | INFO | batch: 3400/4796 loss: 0.0090843066573143
2023-11-10 09:21:32,964 | train | INFO | batch: 3500/4796 loss: 0.009667234495282173
2023-11-10 09:24:16,452 | train | INFO | batch: 3600/4796 loss: 0.01811429113149643
2023-11-10 09:26:59,052 | train | INFO | batch: 3700/4796 loss: 0.009967086836695671
2023-11-10 09:29:42,360 | train | INFO | batch: 3800/4796 loss: 0.0063539426773786545
2023-11-10 09:32:25,231 | train | INFO | batch: 3900/4796 loss: 0.01839161105453968
2023-11-10 09:35:08,159 | train | INFO | batch: 4000/4796 loss: 0.013014295138418674
2023-11-10 09:37:50,909 | train | INFO | batch: 4100/4796 loss: 0.07424542307853699
2023-11-10 09:40:35,591 | train | INFO | batch: 4200/4796 loss: 0.014184113591909409
2023-11-10 09:43:18,146 | train | INFO | batch: 4300/4796 loss: 0.012123394757509232
2023-11-10 09:46:01,154 | train | INFO | batch: 4400/4796 loss: 0.035521842539310455
2023-11-10 09:48:44,523 | train | INFO | batch: 4500/4796 loss: 0.008235432207584381
2023-11-10 09:51:27,698 | train | INFO | batch: 4600/4796 loss: 0.022879544645547867
2023-11-10 09:54:09,585 | train | INFO | batch: 4700/4796 loss: 0.013669073581695557
2023-11-10 09:56:44,726 | train | INFO | --Val 2/5
2023-11-10 09:56:45,905 | train | INFO | batch: 0/125 loss: 0.00944400206208229
2023-11-10 09:58:41,479 | train | INFO | batch: 100/125 loss: 0.008530843071639538
2023-11-10 09:59:09,150 | train | INFO | Write row 2
2023-11-10 09:59:09,591 | train | INFO | --Train 3/5
2023-11-10 09:59:10,904 | train | INFO | batch: 0/4796 loss: 0.008112384006381035
2023-11-10 10:01:54,475 | train | INFO | batch: 100/4796 loss: 0.0156845860183239
2023-11-10 10:04:37,294 | train | INFO | batch: 200/4796 loss: 0.009554276242852211
2023-11-10 10:07:22,504 | train | INFO | batch: 300/4796 loss: 0.010741807520389557
2023-11-10 10:10:05,240 | train | INFO | batch: 400/4796 loss: 0.007589121349155903
2023-11-10 10:12:48,940 | train | INFO | batch: 500/4796 loss: 0.017766674980521202
2023-11-10 10:15:32,349 | train | INFO | batch: 600/4796 loss: 0.010729662142693996
2023-11-10 10:18:15,808 | train | INFO | batch: 700/4796 loss: 0.024143852293491364
2023-11-10 10:20:57,929 | train | INFO | batch: 800/4796 loss: 0.010775543749332428
2023-11-10 10:23:41,833 | train | INFO | batch: 900/4796 loss: 0.007199387531727552
2023-11-10 10:26:23,822 | train | INFO | batch: 1000/4796 loss: 0.010535835288465023
2023-11-10 10:29:07,188 | train | INFO | batch: 1100/4796 loss: 0.00980438757687807
2023-11-10 10:31:51,663 | train | INFO | batch: 1200/4796 loss: 0.01399923674762249
2023-11-10 10:34:33,915 | train | INFO | batch: 1300/4796 loss: 0.008987894281744957
2023-11-10 10:37:17,461 | train | INFO | batch: 1400/4796 loss: 0.011700625531375408
2023-11-10 10:40:02,001 | train | INFO | batch: 1500/4796 loss: 0.00850219838321209
2023-11-10 10:42:45,829 | train | INFO | batch: 1600/4796 loss: 0.0055392044596374035
2023-11-10 10:45:29,070 | train | INFO | batch: 1700/4796 loss: 0.005783041939139366
2023-11-10 10:48:11,800 | train | INFO | batch: 1800/4796 loss: 0.014801116660237312
2023-11-10 10:50:55,227 | train | INFO | batch: 1900/4796 loss: 0.00997532345354557
2023-11-10 10:53:37,802 | train | INFO | batch: 2000/4796 loss: 0.00749805336818099
2023-11-10 10:56:21,203 | train | INFO | batch: 2100/4796 loss: 0.010274738073348999
2023-11-10 10:59:03,177 | train | INFO | batch: 2200/4796 loss: 0.007263089995831251
2023-11-10 11:01:46,698 | train | INFO | batch: 2300/4796 loss: 0.024935729801654816
2023-11-10 11:04:29,519 | train | INFO | batch: 2400/4796 loss: 0.012332553043961525
2023-11-10 11:07:14,256 | train | INFO | batch: 2500/4796 loss: 0.012678747996687889
2023-11-10 11:09:54,787 | train | INFO | batch: 2600/4796 loss: 0.016315322369337082
2023-11-10 11:12:37,157 | train | INFO | batch: 2700/4796 loss: 0.01204689685255289
2023-11-10 11:15:20,245 | train | INFO | batch: 2800/4796 loss: 0.01799270510673523
2023-11-10 11:18:03,014 | train | INFO | batch: 2900/4796 loss: 0.009443430230021477
2023-11-10 11:20:45,380 | train | INFO | batch: 3000/4796 loss: 0.009180263616144657
2023-11-10 11:23:29,116 | train | INFO | batch: 3100/4796 loss: 0.015558775514364243
2023-11-10 11:26:13,210 | train | INFO | batch: 3200/4796 loss: 0.009893723763525486
2023-11-10 11:28:54,755 | train | INFO | batch: 3300/4796 loss: 0.0774303525686264
2023-11-10 11:31:38,954 | train | INFO | batch: 3400/4796 loss: 0.014717291109263897
2023-11-10 11:34:21,608 | train | INFO | batch: 3500/4796 loss: 0.018413115292787552
2023-11-10 11:37:04,815 | train | INFO | batch: 3600/4796 loss: 0.01082401443272829
2023-11-10 11:39:48,074 | train | INFO | batch: 3700/4796 loss: 0.028608012944459915
2023-11-10 11:42:29,195 | train | INFO | batch: 3800/4796 loss: 0.020146258175373077
2023-11-10 11:45:11,232 | train | INFO | batch: 3900/4796 loss: 0.011735511012375355
2023-11-10 11:47:52,968 | train | INFO | batch: 4000/4796 loss: 0.01698712445795536
2023-11-10 11:50:35,746 | train | INFO | batch: 4100/4796 loss: 0.01305604912340641
2023-11-10 11:53:18,174 | train | INFO | batch: 4200/4796 loss: 0.008187965489923954
2023-11-10 11:56:01,495 | train | INFO | batch: 4300/4796 loss: 0.008718336001038551
2023-11-10 11:58:45,214 | train | INFO | batch: 4400/4796 loss: 0.007499896455556154
2023-11-10 12:01:28,824 | train | INFO | batch: 4500/4796 loss: 0.03738222271203995
2023-11-10 12:04:13,998 | train | INFO | batch: 4600/4796 loss: 0.015762997791171074
2023-11-10 12:06:57,316 | train | INFO | batch: 4700/4796 loss: 0.047318801283836365
2023-11-10 12:09:33,228 | train | INFO | --Val 3/5
2023-11-10 12:09:34,424 | train | INFO | batch: 0/125 loss: 0.008346009999513626
2023-11-10 12:11:30,336 | train | INFO | batch: 100/125 loss: 0.009737909771502018
2023-11-10 12:11:58,111 | train | INFO | Write row 3
2023-11-10 12:11:58,569 | train | INFO | --Train 4/5
2023-11-10 12:11:59,847 | train | INFO | batch: 0/4796 loss: 0.004919004160910845
2023-11-10 12:14:42,360 | train | INFO | batch: 100/4796 loss: 0.008501010946929455
2023-11-10 12:17:26,818 | train | INFO | batch: 200/4796 loss: 0.01328551210463047
2023-11-10 12:20:09,677 | train | INFO | batch: 300/4796 loss: 0.007377315312623978
2023-11-10 12:22:50,639 | train | INFO | batch: 400/4796 loss: 0.012634663842618465
2023-11-10 12:25:33,137 | train | INFO | batch: 500/4796 loss: 0.010568267665803432
2023-11-10 12:28:14,989 | train | INFO | batch: 600/4796 loss: 0.008929464034736156
2023-11-10 12:30:58,927 | train | INFO | batch: 700/4796 loss: 0.014855724759399891
2023-11-10 12:33:41,728 | train | INFO | batch: 800/4796 loss: 0.013481290079653263
2023-11-10 12:36:23,933 | train | INFO | batch: 900/4796 loss: 0.0116139966994524
2023-11-10 12:39:07,275 | train | INFO | batch: 1000/4796 loss: 0.008757355622947216
2023-11-10 12:41:49,502 | train | INFO | batch: 1100/4796 loss: 0.014131455682218075
2023-11-10 12:44:31,530 | train | INFO | batch: 1200/4796 loss: 0.008728178218007088
2023-11-10 12:47:15,483 | train | INFO | batch: 1300/4796 loss: 0.009094041772186756
2023-11-10 12:49:58,826 | train | INFO | batch: 1400/4796 loss: 0.008358403109014034
2023-11-10 12:52:42,788 | train | INFO | batch: 1500/4796 loss: 0.007771885488182306
2023-11-10 12:55:26,531 | train | INFO | batch: 1600/4796 loss: 0.016882149502635002
2023-11-10 12:58:10,528 | train | INFO | batch: 1700/4796 loss: 0.008230037987232208
2023-11-10 13:00:54,154 | train | INFO | batch: 1800/4796 loss: 0.011745139956474304
2023-11-10 13:03:37,890 | train | INFO | batch: 1900/4796 loss: 0.01640385016798973
2023-11-10 13:06:20,602 | train | INFO | batch: 2000/4796 loss: 0.009335957467556
2023-11-10 13:09:03,499 | train | INFO | batch: 2100/4796 loss: 0.013370836153626442
2023-11-10 13:11:45,063 | train | INFO | batch: 2200/4796 loss: 0.011445381678640842
2023-11-10 13:14:28,984 | train | INFO | batch: 2300/4796 loss: 0.021426700055599213
2023-11-10 13:17:13,273 | train | INFO | batch: 2400/4796 loss: 0.008993425406515598
2023-11-10 13:19:58,158 | train | INFO | batch: 2500/4796 loss: 0.009223591536283493
2023-11-10 13:22:42,634 | train | INFO | batch: 2600/4796 loss: 0.015694446861743927
2023-11-10 13:25:26,337 | train | INFO | batch: 2700/4796 loss: 0.013199420645833015
2023-11-10 13:28:09,967 | train | INFO | batch: 2800/4796 loss: 0.05422644317150116
2023-11-10 13:30:53,418 | train | INFO | batch: 2900/4796 loss: 0.010850924998521805
2023-11-10 13:33:38,385 | train | INFO | batch: 3000/4796 loss: 0.00973974633961916
2023-11-10 13:36:21,985 | train | INFO | batch: 3100/4796 loss: 0.007751221768558025
2023-11-10 13:39:04,421 | train | INFO | batch: 3200/4796 loss: 0.027049662545323372
2023-11-10 13:41:48,502 | train | INFO | batch: 3300/4796 loss: 0.01335589587688446
2023-11-10 13:44:30,930 | train | INFO | batch: 3400/4796 loss: 0.009076723828911781
2023-11-10 13:47:13,463 | train | INFO | batch: 3500/4796 loss: 0.011263944208621979
2023-11-10 13:49:58,441 | train | INFO | batch: 3600/4796 loss: 0.009065832942724228
2023-11-10 13:52:42,489 | train | INFO | batch: 3700/4796 loss: 0.00893251970410347
2023-11-10 13:55:25,973 | train | INFO | batch: 3800/4796 loss: 0.00896618701517582
2023-11-10 13:58:08,257 | train | INFO | batch: 3900/4796 loss: 0.007595259230583906
2023-11-10 14:00:51,308 | train | INFO | batch: 4000/4796 loss: 0.0078072454780340195
2023-11-10 14:03:33,932 | train | INFO | batch: 4100/4796 loss: 0.006598564796149731
2023-11-10 14:06:17,372 | train | INFO | batch: 4200/4796 loss: 0.007698146626353264
2023-11-10 14:08:58,900 | train | INFO | batch: 4300/4796 loss: 0.01899394579231739
2023-11-10 14:11:42,140 | train | INFO | batch: 4400/4796 loss: 0.01684572361409664
2023-11-10 14:14:23,982 | train | INFO | batch: 4500/4796 loss: 0.022764122113585472
2023-11-10 14:17:05,557 | train | INFO | batch: 4600/4796 loss: 0.007865672931075096
2023-11-10 14:19:49,310 | train | INFO | batch: 4700/4796 loss: 0.010452624410390854
2023-11-10 14:22:25,366 | train | INFO | --Val 4/5
2023-11-10 14:22:26,547 | train | INFO | batch: 0/125 loss: 0.008978737518191338
2023-11-10 14:24:22,361 | train | INFO | batch: 100/125 loss: 0.009941446594893932
2023-11-10 14:24:50,182 | train | INFO | Write row 4
2023-11-10 14:24:51,217 | train | INFO | Recorder, epoch 4 Model saved: /home/kwy00/ysy/results/train/20231110_031722/model.pt
