"lr starts with 2.0e-4 and finish with 1.0e-4" -> 7epochs with same 1.0e-4 lr training following original linearLR-Multistep-scheme

compare this result to cosine annealing method which has gradual decay on learning rate or multistepLR with [6, 10, 15, 20, 25, 30, 35, 40] scheme
