{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ea4d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a753fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16b6a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "sample = pd.read_csv('/home/kwy00/ysy/sample_submission.csv')\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e59aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "test_filepath = '/home/kwy00/ysy/test/'\n",
    "train_filepath = '/home/kwy00/ysy/train/'\n",
    "# valid_filepath = '/home/kwy00/ysy/valid/' # after running preprocessing\n",
    "\n",
    "test_list = os.listdir(test_filepath)\n",
    "train_list = os.listdir(train_filepath)\n",
    "# valid_list = os.listdir(valid_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b89c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file_count = len(test_list)\n",
    "train_file_count = len(train_list)\n",
    "# valid_file_count = len(valid_list)\n",
    "\n",
    "print(\"number of test file : \", test_file_count)\n",
    "print(\"number of train file : \", train_file_count)\n",
    "# print(\"number of valid file : \", valid_file_count\")\n",
    "\n",
    "print(\"number of images in train : \", (int)(train_file_count/2)) # rest half consist of txt file which contains label info.\n",
    "# print(\"number of images in valid : \", (int)(valid_file_count/2))\n",
    "\n",
    "print(\"total image file : \", test_file_count+(int)(train_file_count/2))\n",
    "# print(\"total image file : \", test_file_count+(int)(train_file_count/2)+(int)(valid_file_count/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153e0919",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/kwy00/ysy/classes.txt\") as f:\n",
    "  class_label = f.read()\n",
    "print(class_label)\n",
    "\n",
    "# chevrolet : malibu      2012~2016   000\n",
    "#             malibu      2017~2019   001\n",
    "#             spark       2016~2021   002\n",
    "#             trailblazer 2021        003\n",
    "#             trax        2017~2019   004\n",
    "# genesis     g80         2016~2020   005\n",
    "#             g80         2021        006\n",
    "#             gv80        2020        007\n",
    "# hyundai     avante      2011~2015   008\n",
    "#             avante      2020        009\n",
    "#             grandeur    2011~2016   010\n",
    "#             grandstarex 2018~2020   011\n",
    "#             ioniq       2016~2019   012\n",
    "#             sonata      2004~2009   013\n",
    "#             sonata      2010~2014   014\n",
    "#             sonata      2019~2020   015\n",
    "# kia         carnival    2015~2020   016\n",
    "#             carnival    2021        017\n",
    "#             k5          2010~2015   018\n",
    "#             k5          2020        018\n",
    "#             k7          2016~2020   020\n",
    "#             mohave      2020        021\n",
    "#             morning     2004~2010   022\n",
    "#             morning     2011~2016   023\n",
    "#             ray         2012~2017   024\n",
    "#             sorrento    2015~2019   025\n",
    "#             sorrento    2020        026\n",
    "#             soul        2014~2018   027\n",
    "#             sportage    2016~2020   028\n",
    "#             stonic      2017~2019   029\n",
    "# renault     sm3         2015~2018   030\n",
    "#             xm3         2020        031\n",
    "# ssangyong   korando     2019~2020   032\n",
    "#             tivoli      2016~2020   033"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f3d20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "ex_image = Image.open(train_filepath + '/syn_00010.png')\n",
    "ex_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21442b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "png_file_list = [] # for train\n",
    "txt_file_list = []\n",
    "for files in train_list:\n",
    "  if (files[-3:] == 'txt'):\n",
    "    txt_file_list.append(files)\n",
    "  else:\n",
    "    png_file_list.append(files)\n",
    "\n",
    "print(len(png_file_list))\n",
    "print(png_file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86527207",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b8da55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51e798e",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_index = 50\n",
    "print_count = 10\n",
    "\n",
    "columns = 3\n",
    "rows = (int)(print_count/columns) + 1\n",
    "plt.figure(figsize=(20, 20))\n",
    "\n",
    "image_index = 0\n",
    "for i in range(start_index, start_index+print_count):\n",
    "  image_index = image_index + 1\n",
    "  title = \"Image{}\".format(image_index)\n",
    "  image = Image.open(train_filepath + png_file_list[i]) # bring image from folder\n",
    "  plt.subplot(rows, columns, image_index) # subplot\n",
    "  plt.title(title)\n",
    "\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "  plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140c7bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check image features\n",
    "from PIL import Image\n",
    "\n",
    "image = Image.open('./train/syn_00001.png')\n",
    "print(\"image_2 format: \", image.format)\n",
    "print(\"image_2 mode: \", image.mode)\n",
    "print(\"image_2 size: \", image.size)\n",
    "\n",
    "image2 = Image.open('./train/syn_00002.png')\n",
    "print(\"image_2 format: \", image2.format)\n",
    "print(\"image_2 mode : \", image2.mode)\n",
    "print(\"image_2 size : \", image2.size)\n",
    "\n",
    "# all images have same size for 1920x1040 and RGBA mode, png format\n",
    "for png_img in png_file_list:\n",
    "    img = Image.open('./train/' + png_img)\n",
    "    if img.size != (1920, 1040):\n",
    "        print(\"image size different! \", png_img)\n",
    "    if img.mode != 'RGBA':\n",
    "        print(\"image mode different! \", png_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16da59f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30de00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# for data augmentation and image drawing and reading\n",
    "import cv2\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b10fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_boxes_on_image(image_path, annotation_path):\n",
    "    # 이미지 불러오기\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # txt 파일에서 Class ID와 Bounding Box 정보 읽기\n",
    "    with open(annotation_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    for line in lines:\n",
    "        values = list(map(float, line.strip().split(' ')))\n",
    "        class_id = int(values[0])\n",
    "        x_min, y_min = int(round(values[1])), int(round(values[2]))\n",
    "        x_max, y_max = int(round(max(values[3], values[5], values[7]))), int(round(max(values[4], values[6], values[8])))\n",
    "\n",
    "        # 이미지에 바운딩 박스 그리기\n",
    "        cv2.rectangle(image, (x_min, y_min), (x_max, y_max), (255, 0, 0), 2)\n",
    "        cv2.putText(image, str(class_id), (x_min, y_min - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "\n",
    "    # 이미지와 바운딩 박스 출력\n",
    "    plt.figure(figsize=(25, 25))\n",
    "    plt.imshow(image)\n",
    "    plt.show()\n",
    "\n",
    "# 파일 경로 설정\n",
    "image_file = './train/syn_00001.png'\n",
    "annotation_file = './train/syn_00001.txt'\n",
    "\n",
    "# 함수 실행\n",
    "draw_boxes_on_image(image_file, annotation_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6656fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################\n",
    "#               define augmentation               #\n",
    "###################################################\n",
    "\n",
    "# reference : https://albumentations.ai/docs/api_reference/augmentations/transforms/\n",
    "    \n",
    "randomly_shuffle_color_transforms = A.Compose([\n",
    "        A.augmentations.transforms.ChannelShuffle(0.25), # 25% randomly shuffles\n",
    "        A.Resize(CFG['IMG_SIZE'], CFG['IMG_SIZE']),\n",
    "    ], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['labels']))\n",
    "\n",
    "contrast_enhancement_transforms = A.Compose([\n",
    "        A.augmentations.transforms.CLAHE(clip_limit=3.0, p=0.9), # clip_limit=3.0, p=0.5 is default\n",
    "        A.Resize(CFG['IMG_SIZE'], CFG['IMG_SIZE']),\n",
    "    ], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['labels']))\n",
    "\n",
    "image_embossing_transforms = A.Compose([\n",
    "        A.augmentations.transforms.Emboss(alpha=(0.2, 0.3), p=0.8),\n",
    "        A.resize(CFG['IMG_SIZE'], CFG['IMG_SIZE']),\n",
    "    ], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['labels']))\n",
    "\n",
    "default_transforms = A.Compose([\n",
    "        # A.augmentations.transforms.ISONoise(p=1.0),\n",
    "        A.Resize(CFG['IMG_HEIGHT_SIZE'], CFG['IMG_WIDTH_SIZE']), # baseline resize to (512 x 512)\n",
    "    ], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['labels']))\n",
    "    \n",
    "\n",
    "default_transforms_v2 = A.Compose([\n",
    "        A.augmentations.geometric.transforms.HorizontalFlip(p=0.2),\n",
    "        A.Resize(CFG['IMG_HEIGHT_SIZE'], CFG['IMG_WIDTH_SIZE']), # baseline resize to (512 x 512)    \n",
    "    ], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['labels']))\n",
    "\n",
    "decreasing_image_quality_transforms = A.Compose([\n",
    "        # A.augmentations.transforms.Downscale(scale_min=0.5, scale_max=0.5, p=0.75),\n",
    "        A.augmentations.transforms.PixelDropout(dropout_prob=0.5, drop_value=0, p=0.5),\n",
    "        # A.augmentations.transforms.GaussNoise(p=0.2),\n",
    "    ], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['labels']))\n",
    "\n",
    "colorjitter_transforms = A.Compose([\n",
    "        A.augmentations.transforms.ColorJitter(brightness=(0.5, 1.5), contrast=(0.5, 1.2),\n",
    "                                        saturation=(0.5, 1.2), hue=0.0,\n",
    "                                        always_apply=False, p=1.0),\n",
    "        A.Resize(CFG['IMG_HEIGHT_SIZE'], CFG['IMG_WIDTH_SIZE'])\n",
    "    ], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['labels']))\n",
    "\n",
    "bboxsafe_cropping_transforms = A.Compose([\n",
    "            A.augmentations.crops.transforms.BBoxSafeRandomCrop(p=1.0),\n",
    "            A.Resize(CFG['IMG_HEIGHT_SIZE'], CFG['IMG_WIDTH_SIZE']),\n",
    "        ], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['labels'],\n",
    "                                    min_area=2048, min_visibility=0.2))\n",
    "\n",
    "bbox_nearcrop_transforms = A.Compose([\n",
    "            A.augmentations.crops.transforms.RandomCropNearBBox(max_part_shift=(0.3, 0.3), p=1.0),\n",
    "            A.Resize(CFG['IMG_HEIGHT_SIZE'], CFG['IMG_WIDTH_SIZE']),\n",
    "        ], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['labels'],\n",
    "                                    min_area=2048, min_visibility=0.2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd230e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = './train'\n",
    "\n",
    "IMGS = sorted(glob.glob(ROOT+'/*.png'))\n",
    "BOXES = sorted(glob.glob(ROOT+'/*.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866f8134",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_boxes(self, box_path):\n",
    "    with open(box_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    boxes = []\n",
    "    labels = []\n",
    "\n",
    "    for line in lines:\n",
    "        values = list(map(float, line.strip().split(' ')))\n",
    "        class_id = int(values[0])\n",
    "        x_min, y_min = int(round(values[1])), int(round(values[2]))\n",
    "        x_max, y_max = int(round(max(values[3], values[5], values[7]))), int(round(max(values[4], values[6], values[8])))\n",
    "\n",
    "        boxes.append([x_min, y_min, x_max, y_max])\n",
    "        labels.append(class_id)\n",
    "\n",
    "    return torch.tensor(boxes, dtype=torch.float32), torch.tensor(labels, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3884b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawing_tool(image, boxes, labels):\n",
    "    \n",
    "    for box, label in (boxes,labels):    \n",
    "        \n",
    "        class_id = label\n",
    "        x_min, y_min = int(round(box[1])), int(round(box[2]))\n",
    "        x_max, y_max = int(round(max(box[3], box[5], box[7]))), int(round(max(box[4], box[6], box[8])))\n",
    "\n",
    "        # 이미지에 바운딩 박스 그리기\n",
    "        cv2.rectangle(image, (x_min, y_min), (x_max, y_max), (255, 0, 0), 2)\n",
    "        cv2.putText(image, str(class_id), (x_min, y_min - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "\n",
    "    # 이미지와 바운딩 박스 출력\n",
    "    plt.figure(figsize=(25, 25))\n",
    "    plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465e05d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "IDX = 1\n",
    "    \n",
    "img_path = IMGS[IDX]\n",
    "file_name = img_path.split('/')[-1]\n",
    "\n",
    "img = cv2.imread(IMGS[IDX])\n",
    "\n",
    "# convert image color mode (BGR -> RGB)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.uint8)\n",
    "\n",
    "height, width = img.shape[0], img.shape[1]\n",
    "box_path = BOXES[IDX]\n",
    "boxes, labels = parse_boxes(box_path)\n",
    "\n",
    "labels += 1 # Background = 0, add background label as 0\n",
    "\n",
    "transformed = colorjitter_transforms(image=img, bboxes=boxes, labels=labels)\n",
    "img, boxes, labels = transformed[\"image\"], transformed[\"bboxes\"], transformed[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d629e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "drawing_tool(img, boxes, labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
