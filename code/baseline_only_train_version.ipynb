{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a4766ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0+cu121\n"
     ]
    }
   ],
   "source": [
    "%pwd\n",
    "\n",
    "# Check Pytorch Version #\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "\n",
    "# move path for training (. = '/home/kwy00/ysy/')\n",
    "%cd /home/kwy00/ysy\n",
    "\n",
    "!ls -l\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# import models for detection\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor, FasterRCNN\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "from torchvision.models.detection.backbone_utils import resnet_fpn_backbone\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "\n",
    "# for data augmentation and image drawing and reading\n",
    "import cv2\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "from tqdm.auto import tqdm\n",
    "from torchmetrics.detection import MeanAveragePrecision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24b8964e",
   "metadata": {
    "id": "XMyNaX1ATADI"
   },
   "outputs": [],
   "source": [
    "# get cuda device if nvidia gpu is available\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "f71f5ac4",
   "metadata": {
    "id": "N0Tx2F6BTAGf"
   },
   "outputs": [],
   "source": [
    "#####################################################\n",
    "#              Training Configuration               #\n",
    "##################################################### \n",
    "\n",
    "# define configuration setting here\n",
    "# NUM_CLASSS = 34, SEED = 41 cannot be changed\n",
    "\n",
    "CFG = {\n",
    "    'NUM_CLASS':34,\n",
    "    'IMG_SIZE':512,\n",
    "    'EPOCHS':10, \n",
    "    'LR':3e-4,\n",
    "    'BATCH_SIZE':8,\n",
    "    'SEED':41\n",
    "}\n",
    "\n",
    "\n",
    "# setting seeds for random\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(CFG['SEED']) # Seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d449fa1",
   "metadata": {
    "id": "R3oQwv1STAM5"
   },
   "outputs": [],
   "source": [
    "def draw_boxes_on_image(image_path, annotation_path):\n",
    "    # 이미지 불러오기\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # txt 파일에서 Class ID와 Bounding Box 정보 읽기\n",
    "    with open(annotation_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    for line in lines:\n",
    "        values = list(map(float, line.strip().split(' ')))\n",
    "        class_id = int(values[0])\n",
    "        x_min, y_min = int(round(values[1])), int(round(values[2]))\n",
    "        x_max, y_max = int(round(max(values[3], values[5], values[7]))), int(round(max(values[4], values[6], values[8])))\n",
    "\n",
    "        # 이미지에 바운딩 박스 그리기\n",
    "        cv2.rectangle(image, (x_min, y_min), (x_max, y_max), (255, 0, 0), 2)\n",
    "        cv2.putText(image, str(class_id), (x_min, y_min - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "\n",
    "    # 이미지와 바운딩 박스 출력\n",
    "    plt.figure(figsize=(25, 25))\n",
    "    plt.imshow(image)\n",
    "    plt.show()\n",
    "\n",
    "# 파일 경로 설정\n",
    "image_file = './train/syn_00001.png'\n",
    "annotation_file = './train/syn_00001.txt'\n",
    "\n",
    "# 함수 실행\n",
    "draw_boxes_on_image(image_file, annotation_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7d38d006",
   "metadata": {
    "id": "FEUUT_q6TATI"
   },
   "outputs": [],
   "source": [
    "#####################################################\n",
    "#                  define dataset                   #\n",
    "#####################################################\n",
    "\n",
    "# here getting data source from hw storage.\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, root, train=True, valid=False, transforms=None):\n",
    "        # root path\n",
    "        self.root = root\n",
    "        self.train = train\n",
    "        self.valid = valid\n",
    "        self.transform_args = transforms\n",
    "        \n",
    "        # image data\n",
    "        self.imgs = sorted(glob.glob(root+'/*.png'))\n",
    "\n",
    "        if train or valid: # both train, valid requires txt annotation.\n",
    "            self.boxes = sorted(glob.glob(root+'/*.txt'))\n",
    "        \n",
    "            \n",
    "    # only create labels for detection (class, bbox location(four edges))\n",
    "    def parse_boxes(self, box_path):\n",
    "        with open(box_path, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "\n",
    "        boxes = []\n",
    "        labels = []\n",
    "\n",
    "        for line in lines:\n",
    "            values = list(map(float, line.strip().split(' ')))\n",
    "            class_id = int(values[0])\n",
    "            x_min, y_min = int(round(values[1])), int(round(values[2]))\n",
    "            x_max, y_max = int(round(max(values[3], values[5], values[7]))), int(round(max(values[4], values[6], values[8])))\n",
    "\n",
    "            boxes.append([x_min, y_min, x_max, y_max])\n",
    "            labels.append(class_id)\n",
    "\n",
    "        return torch.tensor(boxes, dtype=torch.float32), torch.tensor(labels, dtype=torch.int64)\n",
    "    \n",
    "    # make dataset(image, label each + transforms)\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        img_path = self.imgs[idx]\n",
    "        img = cv2.imread(self.imgs[idx])\n",
    "        # convert image color mode (BGR -> RGB)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        \n",
    "        # RGB color feature normalization\n",
    "        img /= 255.0\n",
    "        height, width = img.shape[0], img.shape[1]\n",
    "        \n",
    "\n",
    "        if self.train or self.valid:\n",
    "            # from annotation path\n",
    "            box_path = self.boxes[idx]\n",
    "            boxes, labels = self.parse_boxes(box_path)\n",
    "            labels += 1 # Background = 0, add background label as 0\n",
    "            \n",
    "            if self.transform_args is not None:\n",
    "                transformed = self.transform_args(image=img, bboxes=boxes, labels=labels)\n",
    "                img, boxes, labels = transformed[\"image\"], transformed[\"bboxes\"], transformed[\"labels\"]\n",
    "\n",
    "            return img, torch.tensor(boxes, dtype=torch.float32), torch.tensor(labels, dtype=torch.int64)\n",
    "        else:\n",
    "            if self.transform_args is not None:\n",
    "                transformed = self.transform_args(image=img)\n",
    "                img = transformed[\"image\"]\n",
    "            file_name = img_path.split('/')[-1]\n",
    "            return file_name, img, width, height\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "    \n",
    "    \n",
    "# define function that couple train image and its label(for classification, bbox edge location)\n",
    "# used for dataloader collate function\n",
    "def collate_fn(batch):\n",
    "    images, targets_boxes, targets_labels = tuple(zip(*batch))\n",
    "    # stacking 2D image for total 3D (batch_size, image_width, image_height, image_features)\n",
    "    images = torch.stack(images, 0)\n",
    "    targets = []\n",
    "\n",
    "    for i in range(len(targets_boxes)):\n",
    "        target = {\n",
    "            \"boxes\": targets_boxes[i],\n",
    "            \"labels\": targets_labels[i]\n",
    "        }\n",
    "        \n",
    "        targets.append(target)\n",
    "\n",
    "    return images, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "8a3a2285",
   "metadata": {
    "id": "O6iSPq4vTAWU"
   },
   "outputs": [],
   "source": [
    "###################################################\n",
    "#               define augmentation               #\n",
    "###################################################\n",
    "\n",
    "# define data transformation(augmentation) here!\n",
    "# used for CustomDataset transforms args\n",
    "# if you want to augment data amount, you need to define transformation method indiviually (A.Compose()!)\n",
    "\n",
    "def get_train_transforms():\n",
    "    return A.Compose([\n",
    "        A.Resize(CFG['IMG_SIZE'], CFG['IMG_SIZE']), # resize to (512 x 512)\n",
    "        ToTensorV2(), # albumentations pytorch transforms ToTensorV2()\n",
    "        \n",
    "        # bounding box format: pascal_voc, label_fields: 'labels'\n",
    "    ], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['labels']))\n",
    "\n",
    "def get_valid_transforms():\n",
    "    return A.Compose([\n",
    "        A.Resize(CFG['IMG_SIZE'], CFG['IMG_SIZE']),\n",
    "        ToTensorV2(), \n",
    "    ], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['labels']))\n",
    "\n",
    "def get_test_transforms():\n",
    "    return A.Compose([\n",
    "        A.Resize(CFG['IMG_SIZE'], CFG['IMG_SIZE']),\n",
    "        ToTensorV2(),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "403042a7",
   "metadata": {
    "id": "8QAupTUCTAcB"
   },
   "outputs": [],
   "source": [
    "###################################################################\n",
    "#                          define model                           #\n",
    "###################################################################\n",
    "\n",
    "# try different model as we need to experiment various model and compare the result. \n",
    "\n",
    "def build_model(num_classes=CFG['NUM_CLASS']+1): # NUM_CLASS + 1 for background label\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True, pretrained_backbone=True) # default resnet50 backbone faster rcnn\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(in_features, num_classes)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "43610179",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "#              define utils tools              #\n",
    "################################################\n",
    "\n",
    "#defined here, util function for saving model and plotting\n",
    "\n",
    "from itertools import product\n",
    "import logging\n",
    "import random\n",
    "import pickle\n",
    "import shutil\n",
    "import json\n",
    "import yaml\n",
    "import csv\n",
    "import os\n",
    "\n",
    "'''\n",
    "File IO\n",
    "'''\n",
    "\n",
    "def save_pickle(path, obj):\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "def load_pickle(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "def save_json(path, obj, sort_keys=True)-> str:  \n",
    "    try:\n",
    "        with open(path, 'w') as f:    \n",
    "            json.dump(obj, f, indent=4, sort_keys=sort_keys)\n",
    "        msg = f\"Json saved {path}\"\n",
    "    except Exception as e:\n",
    "        msg = f\"Fail to save {e}\"\n",
    "    return msg\n",
    "\n",
    "def load_json(path):\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "    \n",
    "'''\n",
    "Logger\n",
    "'''\n",
    "def get_logger(name: str, dir_: str, stream=False) -> logging.RootLogger:\n",
    "    logger = logging.getLogger(name)\n",
    "    logger.setLevel(logging.INFO)\n",
    "    \n",
    "    formatter = logging.Formatter('%(asctime)s | %(name)s | %(levelname)s | %(message)s')\n",
    "    stream_handler = logging.StreamHandler()\n",
    "    file_handler = logging.FileHandler(os.path.join(dir_, f'{name}.log'))\n",
    "    \n",
    "    stream_handler.setFormatter(formatter)\n",
    "    file_handler.setFormatter(formatter)\n",
    "    \n",
    "    if stream:\n",
    "        logger.addHandler(stream_handler)\n",
    "    logger.addHandler(file_handler)\n",
    "    \n",
    "    return logger\n",
    "\n",
    "# No Validation (only use Train data version)\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import torch\n",
    "import csv\n",
    "\n",
    "class Recorder():\n",
    "    def __init__(self,\n",
    "                record_dir:str,\n",
    "                model: object,\n",
    "                optimizer: object,\n",
    "                scheduler: object,\n",
    "                amp: object,\n",
    "                logger: logging.RootLogger=None):\n",
    "        self.record_dir = record_dir\n",
    "        self.plot_dir = os.path.join(record_dir, 'plots')\n",
    "        self.record_filepath = os.path.join(self.record_dir, 'record.csv')\n",
    "        self.weight_path = os.path.join(record_dir, 'model.pt')\n",
    "        \n",
    "        self.logger = logger\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "        self.amp = amp\n",
    "        \n",
    "        os.makedirs(self.plot_dir, exist_ok = True)\n",
    "        \n",
    "    def set_model(self, model: 'model'):\n",
    "        self.model = model\n",
    "        \n",
    "    def set_logger(self, logger: logging.RootLogger):\n",
    "        self.logger = logger\n",
    "        \n",
    "    def create_record_directory(self):\n",
    "        os.makedirs(self.record_dir, exist_ok=True)\n",
    "        \n",
    "        msg = f\"Create directory {self.record_dir}\"\n",
    "        self.logger.info(msg) if self.logger else None\n",
    "        \n",
    "    def add_row(self, row_dict: dict):\n",
    "        fieldnames = list(row_dict.keys())\n",
    "        \n",
    "        with open(self.record_filepath, newline='', mode='a') as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "            \n",
    "            if f.tell() == 0:\n",
    "                writer.writeheader()\n",
    "                \n",
    "            writer.writerow(row_dict)\n",
    "            msg = f\"Write row {row_dict['epoch_index']}\"\n",
    "            self.logger.info(msg) if self.logger else None\n",
    "            \n",
    "    def save_weight(self, epoch:int) -> None:\n",
    "        if self.amp is not None:\n",
    "            check_point = {\n",
    "                'epoch': epoch+1,\n",
    "                'model': self.model.state_dict(),\n",
    "                'optimizer': self.optimizer.state_dict(),\n",
    "                'scheduler': self.scheduler.state_dict() if self.scheduler else None,\n",
    "                'amp': self.amp.state_dict()\n",
    "            }\n",
    "        else:\n",
    "            check_point = {\n",
    "                'epoch': epoch + 1,\n",
    "                'model': self.model.state_dict(),\n",
    "                'optimizer': self.optimizer.state_dict(),\n",
    "                'scheduler': self.scheduler.state_dict() if self.scheduler else None,\n",
    "            }\n",
    "        torch.save(check_point, self.weight_path)\n",
    "        msg = f\"Recorder, epoch {epoch} Model saved: {self.weight_path}\"\n",
    "        self.logger.info(msg) if self.logger else None\n",
    "        \n",
    "    def save_plot(self, plots: list):\n",
    "\n",
    "        record_df = pd.read_csv(self.record_filepath)\n",
    "        current_epoch = record_df['epoch_index'].max()\n",
    "        epoch_range = list(range(0, current_epoch+1))\n",
    "        color_list = ['red', 'blue']  # train, val\n",
    "\n",
    "        for plot_name in plots:\n",
    "            columns = [f'train_{plot_name}']\n",
    "\n",
    "            fig = plt.figure(figsize=(20, 8))\n",
    "            \n",
    "            for id_, column in enumerate(columns):\n",
    "                values = record_df[column].tolist()\n",
    "                plt.plot(epoch_range, values, marker='.', c=color_list[id_], label=column)\n",
    "             \n",
    "            plt.title(plot_name, fontsize=15)\n",
    "            plt.legend(loc='upper right')\n",
    "            plt.grid()\n",
    "            plt.xlabel('epoch')\n",
    "            plt.ylabel(plot_name)\n",
    "            plt.xticks(epoch_range, [str(i) for i in epoch_range])\n",
    "            plt.close(fig)\n",
    "            fig.savefig(os.path.join(self.plot_dir, plot_name +'.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f94d1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No Validation (only train version)\n",
    "\n",
    "from datetime import datetime, timezone, timedelta\n",
    "from time import time\n",
    "import copy\n",
    "\n",
    "def train(model, train_loader, optimizer, \n",
    "          scheduler, train_serial,\n",
    "          logger, recorder, device, interval=100):\n",
    "    \n",
    "    EPOCHS = CFG['EPOCHS'] # training epoch\n",
    "    model.to(device) # allocate model to gpu memory\n",
    "\n",
    "    for epoch in range(0, CFG['EPOCHS']):\n",
    "        \n",
    "        # For Recording..\n",
    "        row_dict = dict()\n",
    "        row_dict['epoch_index'] = epoch\n",
    "        row_dict['train_serial'] = train_serial\n",
    "        \n",
    "        \"\"\"\n",
    "        Train start\n",
    "        \"\"\"\n",
    "        print(f\"Train {epoch}/{EPOCHS}\")\n",
    "        logger.info(f\"--Train {epoch}/{EPOCHS}\")\n",
    "        \n",
    "        # start time recording\n",
    "        start_timestamp = time()\n",
    "        \n",
    "        model.train()\n",
    "        train_loss = []\n",
    "        train_map_arr = []\n",
    "        train_map_50 = []\n",
    "        train_map_75 = []\n",
    "        \n",
    "        # data batch processing\n",
    "        for batch_index, (images, targets) in enumerate(tqdm(train_loader)):\n",
    "            model.train()\n",
    "            images = [img.to(device) for img in images]\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss_dict = model(images, targets)\n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "            losses.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss.append(losses.item())\n",
    "            \n",
    "            if batch_index % interval == 0:\n",
    "                msg = f\"batch: {batch_index}/{len(train_loader)} loss: {losses.item()}\"\n",
    "                logger.info(msg)\n",
    "                \n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                prediction = model(images)\n",
    "            \n",
    "            # metrics for mean Average Precision\n",
    "            metric = MeanAveragePrecision(iou_type='bbox')\n",
    "            metric.update(prediction, targets)\n",
    "            map_dict = metric.compute()\n",
    "            \n",
    "            train_map_arr.append(map_dict['map'])\n",
    "            train_map_50.append(map_dict['map_50'])\n",
    "            train_map_75.append(map_dict['map_75'])\n",
    "        \n",
    "        tr_map = np.mean(train_map_arr)\n",
    "        tr_map_50 = np.mean(train_map_50)\n",
    "        tr_map_75 = np.mean(train_map_75)\n",
    "        tr_loss = np.mean(train_loss)\n",
    "        end_timestamp = time()\n",
    "        \n",
    "        row_dict['train_loss'] = tr_loss\n",
    "        row_dict['train_elapsed_time'] = end_timestamp - start_timestamp\n",
    "        row_dict['train_map'] = tr_map\n",
    "        row_dict['train_map_50'] = tr_map_50\n",
    "        row_dict['train_map_75'] = tr_map_75\n",
    "        \n",
    "        print(f'Epoch [{epoch}] Train loss : [{tr_loss:.5f}]')\n",
    "        print(f'Epoch [{epoch}] Train map: [{tr_map:.5f}]')\n",
    "        print(f'Epoch [{epoch}] Train_50 map : [{tr_map_50:.5f}]')\n",
    "        print(f'Epoch [{epoch}] Train_75 map : [{tr_map_75:.5f}]')\n",
    "        \n",
    "        \"\"\"\n",
    "        Recorder\n",
    "        \"\"\"\n",
    "        recorder.add_row(row_dict)\n",
    "        recorder.save_plot(['loss', 'elapsed_time', 'map', 'map_50', 'map_75'])\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "        \n",
    "        # every epoch finish with 0, we will save model\n",
    "        #if epoch%10 == 0:\n",
    "        #    recorder.save_weight(epoch=epoch)\n",
    "    \n",
    "    recorder.save_weight(epoch=epoch) # if you want to save model at last training\n",
    "    return model\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b07e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timezone, timedelta\n",
    "\n",
    "# root directory\n",
    "ROOT_DIR = '/home/kwy00/ysy/'\n",
    "\n",
    "# define train serial\n",
    "kst = timezone(timedelta(hours=9))\n",
    "train_serial = datetime.now(tz=kst).strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# recorder directory\n",
    "RECORDER_DIR = os.path.join(ROOT_DIR, 'results', 'train', train_serial)\n",
    "os.makedirs(RECORDER_DIR, exist_ok=True)\n",
    "\n",
    "# set logger\n",
    "logger = get_logger(name='train', dir_=RECORDER_DIR, stream=False)\n",
    "logger.info(f\"Set Logger {RECORDER_DIR}\")\n",
    "\n",
    "\n",
    "# dataset instance (transformed dataset for train, valid, test)\n",
    "# if you want to use train data only, simply use ConCatDataset(train, valid)\n",
    "train_dataset = CustomDataset('./train', train=True, valid=False, transforms=get_train_transforms())\n",
    "valid_dataset = CustomDataset('./valid', train=False, valid=True, transforms=get_valid_transforms())\n",
    "test_dataset = CustomDataset('./test', train=False, valid=False, transforms=get_test_transforms())\n",
    "\n",
    "# concat dataset with train and valid -> only train used\n",
    "total_dataset = ConcatDataset([train_dataset, valid_dataset]) # train + valid\n",
    "\n",
    "# create dataloader with batch_size=, shuffle=,\n",
    "train_loader = DataLoader(total_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=True, collate_fn=collate_fn) # collate_fn used here!\n",
    "test_loader = DataLoader(test_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False)\n",
    "\n",
    "logger.info(f\"Load data, train:{len(train_dataset)} val:{len(valid_dataset)}\")\n",
    "\n",
    "# define model\n",
    "model = build_model()\n",
    "\n",
    "# define optimizer and scheduler\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=CFG['LR'])\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "\n",
    "recorder = Recorder(record_dir=RECORDER_DIR, \n",
    "                    model = model,\n",
    "                    optimizer=optimizer,\n",
    "                    scheduler=None,\n",
    "                    amp= None,\n",
    "                    logger=logger)\n",
    "\n",
    "\n",
    "infer_model = train(model, train_loader, optimizer, scheduler,\n",
    "                    train_serial, logger, recorder, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1589ecd6",
   "metadata": {
    "id": "2WJV5GOwTAnl"
   },
   "outputs": [],
   "source": [
    "#########################################################\n",
    "#                define model inference                 #\n",
    "#########################################################\n",
    "def box_denormalize(x1, y1, x2, y2, width, height):\n",
    "    x1 = (x1 / CFG['IMG_SIZE']) * width\n",
    "    y1 = (y1 / CFG['IMG_SIZE']) * height\n",
    "    x2 = (x2 / CFG['IMG_SIZE']) * width\n",
    "    y2 = (y2 / CFG['IMG_SIZE']) * height\n",
    "    return x1.item(), y1.item(), x2.item(), y2.item()\n",
    "\n",
    "\n",
    "predict_timestamp = datetime.now(tz=kst).strftime(\"%Y%m%d_%H%M%S\")\n",
    "predict_serial = train_serial + '_' + predict_timestamp\n",
    "\n",
    "PREDICT_DIR = os.path.join('/home/kwy00/ysy/', 'results', 'predict', predict_serial)\n",
    "os.makedirs(PREDICT_DIR, exist_ok=True)\n",
    "\n",
    "def inference(model, test_loader, device):\n",
    "  \n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    results = pd.read_csv('./sample_submission.csv')\n",
    "\n",
    "    for img_files, images, img_width, img_height in tqdm(iter(test_loader)):\n",
    "        images = [img.to(device) for img in images]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(images)\n",
    "\n",
    "        for idx, output in enumerate(outputs):\n",
    "            boxes = output[\"boxes\"].cpu().numpy()\n",
    "            labels = output[\"labels\"].cpu().numpy()\n",
    "            scores = output[\"scores\"].cpu().numpy()\n",
    "\n",
    "            for box, label, score in zip(boxes, labels, scores):\n",
    "                x1, y1, x2, y2 = box\n",
    "                x1, y1, x2, y2 = box_denormalize(x1, y1, x2, y2, img_width[idx], img_height[idx])\n",
    "                \n",
    "                index_list = list([1])\n",
    "                new_row = pd.DataFrame({\"file_name\": img_files[idx],\n",
    "                                    \"class_id\": label-1,\n",
    "                                    \"confidence\": score,\n",
    "                                    \"point1_x\":x1, \"point1_y\":y1,\n",
    "                                    \"point2_x\":x2, \"point2_y\":y1,\n",
    "                                    \"point3_x\":x2, \"point3_y\":y2,\n",
    "                                    \"point4_x\":x1, \"point4_y\":y2},\n",
    "                                       index=index_list)\n",
    "                \n",
    "                results = pd.concat([results, new_row], ignore_index=True)\n",
    "                \n",
    "                \n",
    "\n",
    "    # 결과를 CSV 파일로 저장\n",
    "    resultpath = os.path.join(PREDICT_DIR, 'baseline_submit.csv')\n",
    "    results.to_csv(resultpath, index=False)\n",
    "    print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "cfd4b0bf",
   "metadata": {
    "id": "MM3hqdkxTAqh"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 11/107 [00:21<03:11,  1.99s/it]"
     ]
    }
   ],
   "source": [
    "inference(infer_model, test_loader, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
